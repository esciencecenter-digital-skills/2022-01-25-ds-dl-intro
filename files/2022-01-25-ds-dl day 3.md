![](https://i.imgur.com/iywjz8s.png)


# 2022-01-25-ds-dl day 3

Welcome to The Workshop Collaborative Document.

This Document is synchronized as you type, so that everyone viewing this page sees the same text. This allows you to collaborate seamlessly on documents.

----------------------------------------------------------------------------

This is the Document for today: [link](https://tinyurl.com/ds-dl-day3)

Collaborative Document day 1: [link](https://tinyurl.com/ds-dl-day1)

Collaborative Document day 2: [link](https://tinyurl.com/ds-dl-day2)

Collaborative Document day 3: [link](https://tinyurl.com/ds-dl-day3)

## üëÆCode of Conduct

* Participants are expected to follow those guidelines:
* Use welcoming and inclusive language.
* Be respectful of different viewpoints and experiences.
* Gracefully accept constructive criticism.
* Focus on what is best for the community.
* Show courtesy and respect towards other community members.
 
## ‚öñÔ∏è License

All content is publicly available under the Creative Commons Attribution License: [creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/).

## üôãGetting help

On how to use HackMD, click on the question-mark icon in the bar above this view.

To ask a question, type `/hand` in the chat window.

To get help, type `/help` in the chat window.

You can ask questions in the document or chat window and helpers will try to help you.

## üñ• Workshop website

[link]([<url>](https://esciencecenter-digital-skills.github.io/2022-01-25-ds-dl-intro/))

üõ† Setup

[link](https://esciencecenter-digital-skills.github.io/2022-01-25-ds-dl-intro/#setup)

Download files

[link](https://esciencecenter-digital-skills.github.io/2021-11-22-ds-dl-intro/#downloading-the-required-datasets)

Post-workshop survey

[link](https://www.surveymonkey.com/r/T9LVRMP)

## üë©‚Äçüè´üë©‚Äçüíªüéì Instructors

Sven van der Burg, Djura Smits

## üßë‚Äçüôã Helpers

Cunliang Geng, Robin Richardson, Giordano Lipari 

## üóìÔ∏è Agenda
| | |
|-|-|
|09:00|Welcome and icebreaker|
|09:15|Finish monitoring the training progress|
|10:15|Coffee break|
|10:30|Networks are like onions|
|11:45|Tea break|
|12:00|Networks are like onions|
|12:45|Recap|
|13:00|END|

## üß† Collaborative Notes

Please open yesterday's notebook - we will finish off the 'Monitoring the training' section first.

### Workflow
7. First perform a prediction
8. Measure the performance

```python=
y_baseline_prediction = X_test['BASEL_sunshine']
```

```python=
plt.figure(figsize=(5, 5), dpi=100)
plt.scatter(y_baseline_prediction, y_test, s=10, alpha=0.5)
plt.xlabel("sunshine hours yesterday")
plt.ylabel("true sunshine hours")
```

```python=
from sklearn.metrics import mean_squared_error

rmse_nn = mean_squared_error(y_test, y_test_predicted, squared=False)

rmse_baseline = mean_squared_error(y_test, y_baseline_prediction, squared=False)

print('NN RMSE:', rmse_nn)
print('BASELINE RMSE:', rmse_baseline)
```

```python=
model = create_nn()
model.compile(loss='mse' \
             optimizer='adam', \
             metrics=[keras.metrics.RootMeanSquaredError()])
```

```python=
history = model.fit(X_train, y_train,
                   batch_size=32,
                   epochs=200,
                   validation_data=(X_val, y_val),
                   verbose=2)
```

Paste this to plot:
```python=
history_df = pd.DataFrame.from_dict(history.history)
sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])
plt.xlabel("epochs")
plt.ylabel("RMSE")
```

You will see the rmse going down, while the validation error increases. This is a classic sign of overfitting.


#### Exercise: Try to reduce the degree of overfitting by lowering the number of parameters
We can keep the network architecture unchanged (2 dense layers + a one-node output layer) and only play with the number of nodes per layer. Try to to run a network with only 10 and 5 nodes in the first and second layer.

1) Is it possible to get rid of overfitting this way?
2) Does the overall performance suffer or does it mostly stay the same?
3) (optional) How low can you go with the number of parameters without notable effect on the performance on the validation set?




### Counteract model overfitting

Edit your NN model to use fewer nodes then run the train and validation plot again:

```python=
model.compile(loss='mse' \
             optimizer='adam', \
             metrics=[keras.metrics.RootMeanSquaredError()])
```

```python=
history = model.fit(X_train, y_train,
                   batch_size=32,
                   epochs=200,
                   validation_data=(X_val, y_val),
                   verbose=2)
```

```python=
history_df = pd.DataFrame.from_dict(history.history)
sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])
plt.xlabel("epochs")
plt.ylabel("RMSE")
```

#### Early stopping: stop at the right time before overfitting

```python=
model = create_nn(100, 50)
model.compile(optimizer='adam', loss='mse', metrics= [keras.metrics.RootMeanSquaredError()])
```

```python=
from tensorflow.keras.callbacks import EarlyStopping
```

```python=
earlystopper = EarlyStopping(
    monitor='val_loss',
    patience=10,
    verbose=1)
```

```python=
history = model.fit(X_train, y_train,
                   batch_size=32,
                   epochs=200,
                   validation_data=(X_val, y_val),
                   callbacks=[earlystopper],
                   verbose=2)
```

```python=
history_df = pd.DataFrame.from_dict(history.history)
sns.lineplot(data=history_df[['root_mean_squared_error', 'val_root_mean_squared_error']])
plt.xlabel("epochs")
plt.ylabel("RMSE")
```


#### Open question: What could be next steps to further improve the model? (breakout rooms)
With unlimited options to modify the model architecture or to play with the training parameters, deep learning can trigger very extensive hunting for better and better results. Usually models are ‚Äúwell behaving‚Äù in the sense that small chances to the architectures also only result in small changes of the performance (if any). It is often tempting to hunt for some magical settings that will lead to much better results. But do those settings exist? Applying common sense is often a good first step to make a guess of how much better could results be. In the present case we might certainly not expect to be able to reliably predict sunshine hours for the next day with 5-10 minute precision. But how much better our model could be exactly, often remains difficult to answer.

- What changes to the model architecture might make sense to explore?
- Ignoring changes to the model architecture, what might notably improve the prediction quality?

##### Answers
|   Room     | Q1  | Q2  |
| --- | --- | --- |
| Room 1 | (1) Remove features that have no predictive value, are unlikely to be correlated with the ouput, and only produce noise . (2) Not using a dense layer (3) The contrary of (1): remove from the training set all other features in Basel?  Kind of removing collinearity.     |  More data   |
| Room 2 | remove irrelevant features from input, increase the number of hidden layers, drop connections, different loss function? |  use more training data, the way to choose training data |
| Room 3 | Adjust the number of layers and nodes while looking at the testing/validation data, dropout layers?  |   give the network a clean dataset and normalize the data   | 
| Room 4 | (1) We reduced the number of nodes already, which improved performance. (2) Another way is to reduce the number of hidden layers, or use dropout. (3) We can change the activation number and/or loss function.(4)  Yet another way is making the batch size bigger which might prevent the network to get stuck in local optima during gradient descent. |2) Having more data might make the model better, more data points per day or more cities. Cleaning the data might also work, for example removing outliers. Data augmentation. |
| Room 5 |   (1) Reduce the number of nodes as discussed earlier (2) Add dropouts to reduce overfitting (3) Perhaps increasing layer depth (while having small number of nodes per layer) could help (4)Having a different loss function which punishes larger errors more (like quadratic or cubic) |  (1) Add more datapoints (2) Different ways of splitting test and training set  (3) Remove noise in data which may corrupt the model (4) Augment data by using simulations if possible |
| Room 6 |   add dropout / reduce connections between input and hidden layers| reduce batch size? more datapoints? find data for the missing columns, kfold validation?, remove columns that might be not relevant  |     |


Sven:
* Remove features that have no predictive value, remove features that are correlated
* More data, data augmentation.
* Adjust the number of layers and nodes. Use dropout!


#### 4. Networks are like onions

Open up a fresh, new notebook!

* Why do we need different types of layers?
* What are good network designs for image data?
* What is a convolutional layer?
* How do we avoid overfitting?

##### Step 0: Familiarizing ourselves with data
```python=
from tensorflow import keras

(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()
```

```python=
len(train_images)
```
We see 50000. Let's pick a subset for training.

```python=
n = 5000
train_images = train_images[:n]
train_labels = train_labels[:n]
```

```python
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

import matplotlib.pyplot as plt
plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.axis('off')
    plt.title(class_names[train_labels[i,0]])
plt.show()
```

##### 1. Formulate the problem
Predicting the class for a given image

##### 2. Identify inputs and outputs
Input: 2D image with colours, Output: the class, one of 10 classes.


#### Exercise: Explore the data

 Familiarize yourself with the CIFAR10 dataset. To start, consider the following questions:
 - What is the dimension of a single data point? What do you think the dimensions mean?
 - What is the range of values that your input data takes?
 - What is the shape of the labels, and how many labels do we have?
 - (Optional) Pre-trained models
Step 4 of our 'deep learning workflow' is: 'Choose a pre-trained model or build a new architecture from scratch'. We are going to build a new architecture from scratch to get you familiar with the convolutional neural network basics. But in the real world you wouldn't do that. So the challenge is: Browse the web for (more) existing architectures or pre-trained models that are likely to work well on this type of data. Try to understand why they work well for this type of data.

Write your answers below:


Sven:
Get dimensions of a single data point:
```python=
train_images.shape
```
5000 images, 32x32 pixels, 3 values for colours (RGB)

Find range of values:
```python=
train_images.min(), train_images.max()
```
0 to 255.

```python=
train_labels.shape
```

```python=
train_labels.min(), train_labels.max()
```
0 to 9.

#### 3. Prepare the data
##### Scaling the data
ML works best with values around 1

```python=
train_images = train_images / 255.0
test_images = test_images / 255.0
```

Now you can check that the values are between 0 and 1:
```python=
train_images.min(), train_images.max()
```

#### 4. Choose a pre-trained model or build a new architecture from scratch
OK, we should use a state-of-the-art convolutional neural network (or transformer)

##### Intuition about convolutional neural layers
```python=
dim = train_images.shape[1] * train_images.shape[2] * train_images.shape[3] 
```

Suppose we create a single Dense (fully connected) layer with 100 hidden units that connect to the input pixels, how many parameters does this layer have?

```python=
3072 * 100 # only the weights of the connections
3072 * 100 + 100 # the weights of the connections + the biases
```
So we would have 307300 parameters.

#### Convolutional layer

##### Exercise: Convolutional neural networks
In groups of 3/4, answer the following questions. Write your answers in the collaborative document.

##### 1. Border pixels
What, do you think, happens to the border pixels when applying a convolution?
##### 2. Number of parameters
Suppose we apply a convolutional layer with 100 kernels of size 3 * 3 * 3 (the last dimension applies to the rgb channels) to our images of 32 * 32 * 3 pixels. How many parameters do we have? Assume, for simplicity, that the kernels do not use bias terms. Compare this to the answer of the previous exercise
##### 3. A small convolutional neural network
So let‚Äôs look at a network with a few convolutional layers. We need to finish with a Dense layer to connect the output cells of the convolutional layer to the outputs for our classes.
```python=
inputs = keras.Input(shape=train_images.shape[1:])
x = keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)
x = keras.layers.Conv2D(32, (3, 3), activation='relu')(x)
x = keras.layers.Flatten()(x)
outputs = keras.layers.Dense(10)(x)

model = keras.Model(inputs=inputs, outputs=outputs, name="cifar_model_small")

model.summary()
```
Inspect the network above:

* What do you think is the function of the Flatten layer?
* Which layer has the most parameters? 
* Do you find this intuitive?

##### Answers

|        | Q1  | Q2  | Q3 |
| ------ | --- | --- | --- |
| Room 1 | The Flatten layer is a Class which converts a n-dimensional input into a 1 dimensional array. This is required when working with both convolutional layer and dense layers.    |   The last layer has the highest numbwe of parameter. | Yes because it is a dense connecting layer  |
| Room 2 |  The output of the Convolutional layer is a matrix and needs to be made to the same dimension as the output class  1D|Last one (Dense): 25088 nodes* 10 output classes + 10 biases | Yes since it it a fully connected layer: all outputs (classes) are connected to all of the previous nodes (25088). |
| Room 3 |     |     | |
| Room 4 |  Flatten transforms ND array to 1D array   |  output layer has 250890 params (28 * 28 * 32) * 10 + 10    | |
| Room 5 |   From ND to 1D  |     | |
| Room 6 | The border pixels are removed in the output because the kernel should fit in the image. For a 3x3 kernel, this means that the output is 2 pixels smaller in each direction      | 3 x 3 x 3 x (100 kernels) = 2700 parameters| keras.layers.Flatten() flattens the input to make it a one dimensional array. It is required for the Dense layer that follows it. The dense layer has the most parameters (250890 ).In the dense layer, every node receives every pixel as a separate input, so it makes sense that it grows very big. The convolutional layers only have a single image as an input. |


## 5. Recap & Q&A

### Exercise: Recap
Take a few minutes to write down your thoughts on what we learned about deep learning in this course:
* What questions do you still have?
* Whether there are any incremental improvements that can benefit your projects?
* What‚Äôs nice that we learnt but is overkill for your current work?



## Troubleshooting

### Episode 4. Download the CIFAR-10 image dataset

#### Issue

The command
```python=
(train_images, train_labels), (test_images, test_labels) = (keras.datasets.cifar10.load_data())
```
throws this message
> Exception: URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1125) 

#### Solutions

###### Fix the SSL issue

This solves the ssl issue (thanks Ling!): https://stackoverflow.com/questions/69687794/unable-to-manually-load-cifar10-dataset
```python=
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
```
Before trying the following again:
```python=
from tensorflow import keras

(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()
```
This has been proven to work.

##### Alternative. Manual download and install

This solution path has not been tested.

Download: https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz for instance pasting and copying the URL in your browser search box. Then follow https://titanwolf.org/Network/Articles/Article?AID=11f6e2de-e6a5-40c4-9995-14ffa006126d. 

## üí≠ Feedback

[post-workshop survey](https://www.surveymonkey.com/r/T9LVRMP)

Think about todays lesson, please write (at least) one thing
that went well and (at least) one thing that can be improved.

Think about content (anything you liked or missed), logistics, pace of instructions, instructors/helpers, setup instructions etc.

### What went well:
* NIce intro to CNN's and some keras API.
* I think it was really helpful to understand the basics of CNNs, with help of the exercises and instructions. For example, I didn't know that the network learns the kernels itself, I thought it would get predetermined kernels and it learns how to combine the outputs. 
* Interesting session again. I have the feeling that I could start my own deep learning project now +2
* Helpful examples for convolution
* Great to actually have time for asking questions/ having discussions +2
* Clear explanation about the kernals
* more code comments were included,and share a lot of useful resources +1
* It was a good idea to copy/paste the code for the figures, etc. so that the focus is on NN +1
* Good setup, group size is nice to still be able to have discussions also in the whole group
* I liked your organization, having one instructor and someone who checks the code + having helpers to document and answer questions. 

### What can be improved:
* Maybe it could be helpful to have a couple of images showing how the network "decomposes" a problem into more refined features with less data and more info (some intuition).
* Spend a bit more time showing how the filters (or kernels) are actually applied to images (maybe a short exercise?) +1
* would be great to run the classifier and see how it works with another dataset
* a bit intro about other types of architectures +3
* Above point is a good one, maybe Mask R-CNN? Or more in general about instance/semantic segmentation? I know it impossible to explain every network variation and/or layer type but would be nice to know more about it.
* It would be nice if the teachers's notebooks are available after the course +4
* How to and where to continue if one wants to dive in more 
* Working with own data / examples
## üìö Resources

- [the difference between validation data and test data](https://machinelearningmastery.com/difference-test-validation-datasets/)
- [underfitting and overfitting](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)
- [visualization of convolutional neural networks](https://www.cs.ryerson.ca/~aharley/vis/conv/)

### Some ML challenges or benchmarks
- https://mlcontests.com/
- [Kaggle, machine learning competitions](https://www.kaggle.com/)
- [protein structure prediction](https://predictioncenter.org/)
- [prediction of protein-protein interactions](https://www.ebi.ac.uk/msd-srv/capri/)


### Some courses for deeper learning:
- [Fast AI course: making neural nets uncool again](https://www.fast.ai/)
- [Intro to Deep Learning with PyTorch](https://www.udacity.com/course/deep-learning-pytorch--ud188), the course is quite intuitive
- Coursera courses by Andrew Ng: 
    - [AI for everyone](https://www.coursera.org/learn/ai-for-everyone), for beginners who won't do ML projects but are courious about what AI really is and what AI can do
    - [ML course](https://www.coursera.org/learn/machine-learning) and [DL course](https://www.coursera.org/specializations/deep-learning), quite intensive courses for beginner/intermediate-level researchers who will do ML/DL projects
    - [Structuring Machine Learning Projects](https://www.coursera.org/learn/machine-learning-projects), how to conduct ML projects with useful ML engineering strategies
